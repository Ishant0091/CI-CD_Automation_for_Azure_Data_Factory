trigger:
  batch: false
  branches:
    include:
      - develop #collaboration branch
      - main


pool:
  vmImage: 'ubuntu-latest'


variables:
  - ${{ if eq(variables['build.SourceBranchName'], 'develop') }}:
      - group: adf-dev

  - ${{ if eq(variables['build.SourceBranchName'], 'main') }}:
      - group: adf-prod

  - name: adf_code_path
    value: "$(Build.SourcesDirectory)/data_ops/adf"
    
  - name: adf_package_file_path
    value: "$(Build.SourcesDirectory)/build/"


stages:
  #This is an optional stage in the pipeline where ADF resources such as Linked Services, Pipelines, and Datasets stored in the repository are validated before deployment.
  - stage: Validate_ADF_Code
    pool:
      vmImage: 'windows-latest'
    jobs:
    - job: Build_ADF_Code
      displayName: 'Validating the ADF Code'
      steps:
      - task: BuildADFTask@1
        inputs:
          DataFactoryCodePath: '$(adf_code_path)'
          Action: 'Build'


  # CI Process (Build Stage)
  - stage: Build_And_Publish_ADF_Artifacts
    
    jobs:
    - job: Build_Adf_Arm_Templates
      displayName: 'ADF - ARM template'
      steps:

      # Installs Node and the npm packages saved in your package.json files in the .pipelines folder
      - task: NodeTool@0
        inputs:
          versionSpec: '10.x'
        displayName: 'Install Node.js'

      - task: Npm@1
        inputs:
          command: 'install'
          workingDir: '$(adf_package_file_path)'
          verbose: true
        displayName: 'Install npm package'

      # The next step is to validate all Azure Data Factory resource code in the repository.
      - task: Npm@1
        displayName: 'Validate ADF Code'
        inputs:
          command: 'custom'
          workingDir: '$(adf_package_file_path)'
          customCommand: 'run build validate $(adf_code_path) /subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.DataFactory/factories/$(azure_data_factory_name)' # Change "ADFIntegration" to the name of your root folder, if there is not root folder, remove that part and keep Build.Repository.LocalPath only.

      # The next step is to generate the ARM template from the Azure Data Factory source code.
      - task: Npm@1
        displayName: 'Validate and Generate ARM template'
        inputs:
          command: 'custom'
          workingDir: '$(adf_package_file_path)'
          customCommand: 'run build export $(adf_code_path) /subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.DataFactory/factories/$(azure_data_factory_name) "ArmTemplate"'  # Change "ADFIntegration" to the name of your root folder, if there is not root folder, remove that part.

      # Publish ARM Template as Pipeline Artifact
      - task: PublishPipelineArtifact@1
        displayName: Download Build Artifacts - ADF ARM templates
        inputs:
          targetPath: '$(Build.SourcesDirectory)/build/ArmTemplate'
          artifact: 'adf-artifact-$(Build.BuildNumber)'
          publishLocation: 'pipeline'

  # CD Process (Deployment Stage)
  - stage: Deploy_to_Dev
    condition: and(succeeded(), eq(variables['build.SourceBranchName'], 'develop'))
    displayName: Deploy To Development Environment
    dependsOn: Build_And_Publish_ADF_Artifacts
    jobs: 
      - job: Deploy_Dev
        displayName: 'Deployment - Dev'
        steps:
        - task: DownloadPipelineArtifact@2
          displayName: Download Build Artifacts - ADF ARM templates
          inputs: 
            artifactName: 'adf-artifact-$(Build.BuildNumber)'
            targetPath: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)'

        - task: toggle-adf-trigger@2
          displayName: STOP ADF Triggers before Deployment
          inputs:
            azureSubscription: '$(azure_service_connection_name)'
            ResourceGroupName: '$(resource_group_name)'
            DatafactoryName: '$(azure_data_factory_name)'
            TriggerFilter: '' #Name of the trigger. Leave empty if you want to stop all trigger
            TriggerStatus: 'stop'

        - task: AzureResourceManagerTemplateDeployment@3
          displayName: 'Deploying to Development'
          inputs:
            deploymentScope: 'Resource Group'
            azureResourceManagerConnection: '$(azure_service_connection_name)'
            subscriptionId: '$(azure_subscription_id)'
            action: 'Create Or Update Resource Group'
            resourceGroupName: '$(resource_group_name)'
            location: '$(location)'
            templateLocation: 'Linked artifact'
            csmFile: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)/ARMTemplateForFactory.json'
            csmParametersFile: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)/ARMTemplateParametersForFactory.json'
            overrideParameters: '-factoryName "$(azure_data_factory_name)" -adls_connection_properties_typeProperties_url "https://$(azure_storage_account_name).dfs.core.windows.net/" -databricks_connection_properties_typeProperties_existingClusterId $(azure_databricks_cluster_id) -keyvault_connection_properties_typeProperties_baseUrl "https://$(azure_keyvault_name).vault.azure.net/"'
            deploymentMode: 'Incremental'

        - task: toggle-adf-trigger@2
          inputs:
            azureSubscription: '$(azure_service_connection_name)'
            ResourceGroupName: '$(resource_group_name)'
            DatafactoryName: '$(azure_data_factory_name)'
            TriggerFilter: '' #Name of the trigger. Leave empty if you want to start all trigger
            TriggerStatus: 'start'

  - stage: Deploy_to_Prod
    condition: and(succeeded(), eq(variables['build.SourceBranchName'], 'mainn'))
    displayName: Deploy To Production Environment
    dependsOn: Build_And_Publish_ADF_Artifacts
    jobs: 
      - job: Deploy_Prod
        displayName: 'Deployment - Prod'
        steps:
        - task: DownloadPipelineArtifact@2
          displayName: Download Build Artifacts - ADF ARM templates
          inputs: 
            artifactName: 'adf-artifact-$(Build.BuildNumber)'
            targetPath: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)'

        - task: toggle-adf-trigger@2
          inputs:
            azureSubscription: '$(azure_service_connection_name)'
            ResourceGroupName: '$(resource_group_name)'
            DatafactoryName: '$(azure_data_factory_name)'
            TriggerFilter: '' #Name of the trigger. Leave empty if you want to stop all trigger
            TriggerStatus: 'stop'

        - task: AzureResourceManagerTemplateDeployment@3
          displayName: 'Deploying to Production'
          inputs:
            deploymentScope: 'Resource Group'
            azureResourceManagerConnection: '$(azure_service_connection_name)'
            subscriptionId: '$(azure_subscription_id)'
            action: 'Create Or Update Resource Group'
            resourceGroupName: '$(resource_group_name)'
            location: '$(location)'
            templateLocation: 'Linked artifact'
            csmFile: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)/ARMTemplateForFactory.json'
            csmParametersFile: '$(Pipeline.Workspace)/adf-artifact-$(Build.BuildNumber)/ARMTemplateParametersForFactory.json'
            overrideParameters: '-factoryName "$(azure_data_factory_name)" -adls_connection_properties_typeProperties_url "https://$(azure_storage_account_name).dfs.core.windows.net/" -databricks_connection_properties_typeProperties_existingClusterId $(azure_databricks_cluster_id) -keyvault_connection_properties_typeProperties_baseUrl "https://$(azure_keyvault_name).vault.azure.net/"'
            deploymentMode: 'Incremental'

        - task: toggle-adf-trigger@2
          inputs:
            azureSubscription: '$(azure_service_connection_name)'
            ResourceGroupName: '$(resource_group_name)'
            DatafactoryName: '$(azure_data_factory_name)'
            TriggerFilter: '' #Name of the trigger. Leave empty if you want to start all trigger
            TriggerStatus: 'start'
